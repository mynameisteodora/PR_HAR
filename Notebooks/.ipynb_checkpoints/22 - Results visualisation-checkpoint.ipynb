{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "\n",
    "from utils.constants import *\n",
    "from utils.file_readers import *\n",
    "from utils.data_exploration import *\n",
    "from utils.signal_processing import *\n",
    "from utils.sliding_window import *\n",
    "from utils.stand_norm import *\n",
    "from utils.one_vs_all_training import *\n",
    "from utils.experiment_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising some results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_stats = pd.read_csv(\"../Plots/experiment_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>activity_name</th>\n",
       "      <th>correctness</th>\n",
       "      <th>random_seed</th>\n",
       "      <th>n_train_subjects</th>\n",
       "      <th>n_validation_subjects</th>\n",
       "      <th>n_time_steps</th>\n",
       "      <th>step</th>\n",
       "      <th>n_features</th>\n",
       "      <th>features</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_accuracy_valid</th>\n",
       "      <th>mean_loss_valid</th>\n",
       "      <th>std_accuracy_valid</th>\n",
       "      <th>std_loss_valid</th>\n",
       "      <th>mean_accuracy_test</th>\n",
       "      <th>mean_f1_test</th>\n",
       "      <th>mean_loss_test</th>\n",
       "      <th>std_accuracy_test</th>\n",
       "      <th>std_f1_test</th>\n",
       "      <th>std_loss_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00_sit_to_stand_downsample_16_all_correctness_...</td>\n",
       "      <td>Sit to stand</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912056</td>\n",
       "      <td>0.248081</td>\n",
       "      <td>0.024233</td>\n",
       "      <td>0.067549</td>\n",
       "      <td>0.904055</td>\n",
       "      <td>0.765533</td>\n",
       "      <td>0.258383</td>\n",
       "      <td>0.035780</td>\n",
       "      <td>0.076058</td>\n",
       "      <td>0.093180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_Sit_to_stand_downsample_16_balance_25_128_fi...</td>\n",
       "      <td>Sit to stand</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157308</td>\n",
       "      <td>0.746317</td>\n",
       "      <td>0.017922</td>\n",
       "      <td>0.013474</td>\n",
       "      <td>0.159623</td>\n",
       "      <td>0.274591</td>\n",
       "      <td>0.746376</td>\n",
       "      <td>0.024368</td>\n",
       "      <td>0.035013</td>\n",
       "      <td>0.013384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000_Sit_to_stand_downsample_16_balance_25_128_...</td>\n",
       "      <td>Sit to stand</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925932</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.020597</td>\n",
       "      <td>0.056388</td>\n",
       "      <td>0.923063</td>\n",
       "      <td>0.800918</td>\n",
       "      <td>0.213091</td>\n",
       "      <td>0.035458</td>\n",
       "      <td>0.081283</td>\n",
       "      <td>0.102341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001_Knee_extension_downsample_16_balance_25_12...</td>\n",
       "      <td>Knee extension</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927107</td>\n",
       "      <td>0.192441</td>\n",
       "      <td>0.018155</td>\n",
       "      <td>0.049760</td>\n",
       "      <td>0.930224</td>\n",
       "      <td>0.690850</td>\n",
       "      <td>0.190204</td>\n",
       "      <td>0.032894</td>\n",
       "      <td>0.102842</td>\n",
       "      <td>0.106835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002_Squats_downsample_16_balance_25_128_filters</td>\n",
       "      <td>Squats</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881267</td>\n",
       "      <td>0.311196</td>\n",
       "      <td>0.048398</td>\n",
       "      <td>0.133806</td>\n",
       "      <td>0.893875</td>\n",
       "      <td>0.661732</td>\n",
       "      <td>0.271579</td>\n",
       "      <td>0.039560</td>\n",
       "      <td>0.091391</td>\n",
       "      <td>0.107157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00all_64_filters</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725089</td>\n",
       "      <td>0.860731</td>\n",
       "      <td>0.041283</td>\n",
       "      <td>0.094856</td>\n",
       "      <td>0.726605</td>\n",
       "      <td>0.947329</td>\n",
       "      <td>0.857724</td>\n",
       "      <td>0.064673</td>\n",
       "      <td>0.063130</td>\n",
       "      <td>0.156454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01all_batch_size_64</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695704</td>\n",
       "      <td>0.947230</td>\n",
       "      <td>0.037829</td>\n",
       "      <td>0.084849</td>\n",
       "      <td>0.693636</td>\n",
       "      <td>0.938413</td>\n",
       "      <td>0.942897</td>\n",
       "      <td>0.057487</td>\n",
       "      <td>0.076626</td>\n",
       "      <td>0.136513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00all_window_size_50_400_epochs</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792394</td>\n",
       "      <td>0.654151</td>\n",
       "      <td>0.041164</td>\n",
       "      <td>0.095628</td>\n",
       "      <td>0.803456</td>\n",
       "      <td>0.959464</td>\n",
       "      <td>0.644103</td>\n",
       "      <td>0.066215</td>\n",
       "      <td>0.069602</td>\n",
       "      <td>0.183745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00all_window_size_62_5_400_epochs</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821440</td>\n",
       "      <td>0.569039</td>\n",
       "      <td>0.045877</td>\n",
       "      <td>0.118178</td>\n",
       "      <td>0.830910</td>\n",
       "      <td>0.965301</td>\n",
       "      <td>0.552498</td>\n",
       "      <td>0.066211</td>\n",
       "      <td>0.062277</td>\n",
       "      <td>0.193410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01all_window_size_50_128_filters</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810263</td>\n",
       "      <td>0.609122</td>\n",
       "      <td>0.042960</td>\n",
       "      <td>0.101629</td>\n",
       "      <td>0.815302</td>\n",
       "      <td>0.964934</td>\n",
       "      <td>0.597862</td>\n",
       "      <td>0.064730</td>\n",
       "      <td>0.062228</td>\n",
       "      <td>0.195575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     experiment_name   activity_name  \\\n",
       "0  00_sit_to_stand_downsample_16_all_correctness_...    Sit to stand   \n",
       "1  0_Sit_to_stand_downsample_16_balance_25_128_fi...    Sit to stand   \n",
       "2  000_Sit_to_stand_downsample_16_balance_25_128_...    Sit to stand   \n",
       "3  001_Knee_extension_downsample_16_balance_25_12...  Knee extension   \n",
       "4    002_Squats_downsample_16_balance_25_128_filters          Squats   \n",
       "5                                   00all_64_filters             all   \n",
       "6                                01all_batch_size_64             all   \n",
       "7                    00all_window_size_50_400_epochs             all   \n",
       "8                  00all_window_size_62_5_400_epochs             all   \n",
       "9                   01all_window_size_50_128_filters             all   \n",
       "\n",
       "  correctness  random_seed  n_train_subjects  n_validation_subjects  \\\n",
       "0         all           42                12                      2   \n",
       "1         all           42                12                      2   \n",
       "2         all           42                12                      2   \n",
       "3         all           42                12                      2   \n",
       "4         all           42                12                      2   \n",
       "5         all           42                12                      2   \n",
       "6         all           42                12                      2   \n",
       "7         all           42                12                      2   \n",
       "8         all           42                12                      2   \n",
       "9         all           42                12                      2   \n",
       "\n",
       "   n_time_steps  step  n_features    features  ...  mean_accuracy_valid  \\\n",
       "0            38    19           3  normalised  ...             0.912056   \n",
       "1            38    19           3  normalised  ...             0.157308   \n",
       "2            38    19           3  normalised  ...             0.925932   \n",
       "3            38    19           3  normalised  ...             0.927107   \n",
       "4            38    19           3  normalised  ...             0.881267   \n",
       "5            38    19           3  normalised  ...             0.725089   \n",
       "6            38    19           3  normalised  ...             0.695704   \n",
       "7            50    25           3  normalised  ...             0.792394   \n",
       "8            63    25           3  normalised  ...             0.821440   \n",
       "9            50    25           3  normalised  ...             0.810263   \n",
       "\n",
       "   mean_loss_valid std_accuracy_valid  std_loss_valid  mean_accuracy_test  \\\n",
       "0         0.248081           0.024233        0.067549            0.904055   \n",
       "1         0.746317           0.017922        0.013474            0.159623   \n",
       "2         0.205479           0.020597        0.056388            0.923063   \n",
       "3         0.192441           0.018155        0.049760            0.930224   \n",
       "4         0.311196           0.048398        0.133806            0.893875   \n",
       "5         0.860731           0.041283        0.094856            0.726605   \n",
       "6         0.947230           0.037829        0.084849            0.693636   \n",
       "7         0.654151           0.041164        0.095628            0.803456   \n",
       "8         0.569039           0.045877        0.118178            0.830910   \n",
       "9         0.609122           0.042960        0.101629            0.815302   \n",
       "\n",
       "   mean_f1_test  mean_loss_test  std_accuracy_test  std_f1_test  std_loss_test  \n",
       "0      0.765533        0.258383           0.035780     0.076058       0.093180  \n",
       "1      0.274591        0.746376           0.024368     0.035013       0.013384  \n",
       "2      0.800918        0.213091           0.035458     0.081283       0.102341  \n",
       "3      0.690850        0.190204           0.032894     0.102842       0.106835  \n",
       "4      0.661732        0.271579           0.039560     0.091391       0.107157  \n",
       "5      0.947329        0.857724           0.064673     0.063130       0.156454  \n",
       "6      0.938413        0.942897           0.057487     0.076626       0.136513  \n",
       "7      0.959464        0.644103           0.066215     0.069602       0.183745  \n",
       "8      0.965301        0.552498           0.066211     0.062277       0.193410  \n",
       "9      0.964934        0.597862           0.064730     0.062228       0.195575  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['experiment_name', 'activity_name', 'correctness', 'random_seed',\n",
       "       'n_train_subjects', 'n_validation_subjects', 'n_time_steps', 'step',\n",
       "       'n_features', 'features', 'num_filters', 'kernel_size', 'activation',\n",
       "       'lr', 'batch_size', 'epochs', 'downsample_rate',\n",
       "       'positive_class_weight', 'mean_accuracy_train', 'mean_loss_train',\n",
       "       'std_accuracy_train', 'std_loss_train', 'mean_accuracy_valid',\n",
       "       'mean_loss_valid', 'std_accuracy_valid', 'std_loss_valid',\n",
       "       'mean_accuracy_test', 'mean_f1_test', 'mean_loss_test',\n",
       "       'std_accuracy_test', 'std_f1_test', 'std_loss_test'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_stats.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter for experiments with all losoxv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_stats_all = experiment_stats[experiment_stats['activity_name'] == 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>activity_name</th>\n",
       "      <th>correctness</th>\n",
       "      <th>random_seed</th>\n",
       "      <th>n_train_subjects</th>\n",
       "      <th>n_validation_subjects</th>\n",
       "      <th>n_time_steps</th>\n",
       "      <th>step</th>\n",
       "      <th>n_features</th>\n",
       "      <th>features</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_accuracy_valid</th>\n",
       "      <th>mean_loss_valid</th>\n",
       "      <th>std_accuracy_valid</th>\n",
       "      <th>std_loss_valid</th>\n",
       "      <th>mean_accuracy_test</th>\n",
       "      <th>mean_f1_test</th>\n",
       "      <th>mean_loss_test</th>\n",
       "      <th>std_accuracy_test</th>\n",
       "      <th>std_f1_test</th>\n",
       "      <th>std_loss_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00all_64_filters</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725089</td>\n",
       "      <td>0.860731</td>\n",
       "      <td>0.041283</td>\n",
       "      <td>0.094856</td>\n",
       "      <td>0.726605</td>\n",
       "      <td>0.947329</td>\n",
       "      <td>0.857724</td>\n",
       "      <td>0.064673</td>\n",
       "      <td>0.063130</td>\n",
       "      <td>0.156454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01all_batch_size_64</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695704</td>\n",
       "      <td>0.947230</td>\n",
       "      <td>0.037829</td>\n",
       "      <td>0.084849</td>\n",
       "      <td>0.693636</td>\n",
       "      <td>0.938413</td>\n",
       "      <td>0.942897</td>\n",
       "      <td>0.057487</td>\n",
       "      <td>0.076626</td>\n",
       "      <td>0.136513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00all_window_size_50_400_epochs</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792394</td>\n",
       "      <td>0.654151</td>\n",
       "      <td>0.041164</td>\n",
       "      <td>0.095628</td>\n",
       "      <td>0.803456</td>\n",
       "      <td>0.959464</td>\n",
       "      <td>0.644103</td>\n",
       "      <td>0.066215</td>\n",
       "      <td>0.069602</td>\n",
       "      <td>0.183745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00all_window_size_62_5_400_epochs</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821440</td>\n",
       "      <td>0.569039</td>\n",
       "      <td>0.045877</td>\n",
       "      <td>0.118178</td>\n",
       "      <td>0.830910</td>\n",
       "      <td>0.965301</td>\n",
       "      <td>0.552498</td>\n",
       "      <td>0.066211</td>\n",
       "      <td>0.062277</td>\n",
       "      <td>0.193410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01all_window_size_50_128_filters</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>normalised</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810263</td>\n",
       "      <td>0.609122</td>\n",
       "      <td>0.042960</td>\n",
       "      <td>0.101629</td>\n",
       "      <td>0.815302</td>\n",
       "      <td>0.964934</td>\n",
       "      <td>0.597862</td>\n",
       "      <td>0.064730</td>\n",
       "      <td>0.062228</td>\n",
       "      <td>0.195575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     experiment_name activity_name correctness  random_seed  \\\n",
       "5                   00all_64_filters           all         all           42   \n",
       "6                01all_batch_size_64           all         all           42   \n",
       "7    00all_window_size_50_400_epochs           all         all           42   \n",
       "8  00all_window_size_62_5_400_epochs           all         all           42   \n",
       "9   01all_window_size_50_128_filters           all         all           42   \n",
       "\n",
       "   n_train_subjects  n_validation_subjects  n_time_steps  step  n_features  \\\n",
       "5                12                      2            38    19           3   \n",
       "6                12                      2            38    19           3   \n",
       "7                12                      2            50    25           3   \n",
       "8                12                      2            63    25           3   \n",
       "9                12                      2            50    25           3   \n",
       "\n",
       "     features  ...  mean_accuracy_valid  mean_loss_valid std_accuracy_valid  \\\n",
       "5  normalised  ...             0.725089         0.860731           0.041283   \n",
       "6  normalised  ...             0.695704         0.947230           0.037829   \n",
       "7  normalised  ...             0.792394         0.654151           0.041164   \n",
       "8  normalised  ...             0.821440         0.569039           0.045877   \n",
       "9  normalised  ...             0.810263         0.609122           0.042960   \n",
       "\n",
       "   std_loss_valid  mean_accuracy_test  mean_f1_test  mean_loss_test  \\\n",
       "5        0.094856            0.726605      0.947329        0.857724   \n",
       "6        0.084849            0.693636      0.938413        0.942897   \n",
       "7        0.095628            0.803456      0.959464        0.644103   \n",
       "8        0.118178            0.830910      0.965301        0.552498   \n",
       "9        0.101629            0.815302      0.964934        0.597862   \n",
       "\n",
       "   std_accuracy_test  std_f1_test  std_loss_test  \n",
       "5           0.064673     0.063130       0.156454  \n",
       "6           0.057487     0.076626       0.136513  \n",
       "7           0.066215     0.069602       0.183745  \n",
       "8           0.066211     0.062277       0.193410  \n",
       "9           0.064730     0.062228       0.195575  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_stats_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(experiment_stats_all['n_time_steps'], experiment_stats_all['mean_accuracy_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(experiment_stats_all['n_time_steps'], experiment_stats_all['mean_loss_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(experiment_stats_all['n_time_steps'], experiment_stats_all['mean_accuracy_test'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
